<html>
<head>
<title> Lecture notes - Chapter 11 - I/O</title>
</head>

<BODY>
<h1> Chapter 11 -- I/O</h1>

<pre>

all about I/O
-------------

computers aren't useful unless we can put data into them,
and get results out.

   input --   data to computer
   output --  data from computer


   computer model:
      
       -----        --------
       |CPU| <----> |memory|
       -----   ^    --------
	       |
	       |
	      \ /

	     -----
	     |i/o|
	     -----

examples of input devices:
   keyboard, mouse, network, disk,  scanner, camera, microphone, ??

examples of output devices:
   printer, (terminal) display, network, disk, speakers, ??


simulator has only 2 I/O devices,
  keyboard (for input)
  display  (for output)


ISSUES THAT MUST BE SOLVED:

programmer interface -- simulator has 
 get, getc, put, putc, puts

 these are actually OS implemented procedures.
 (The OS is the program that interfaces between the programmer
  or application user and the actual hardware.  For us on the
  sol/nova machines, it is UNIX.)




protection issues --
  in a real system, there could be more than one terminal
  (terminal is a keyboard and display together)

  Should one user be able to display characters on another's
  display?  Lock up another's keyboard?  Send a file of
  infinite length to the printer, effectively shutting
  all others out?

  In practice, the OS's job is "resource management,"
  allocating all portions of the processor.  Examples
  of resources are the CPU and all I/O devices.


physical issues --
  a computer today (1999) can complete an instruction at
  the rate of about 1 each 10 nsec. (100MHz, or 100 MIPS).
  Unfortunately, typical I/O devices are much slower, often
  requiring 10s of milliseconds to deal with a single
  character. That is more than 1 million times slower!
  This situation is dubbed the "access gap."



disk - a real, live, physical device
------------------------------------

Vocabulary, to form a picture of a disk (ch 11, p294)

  PLATTER -- sort of like a phonograph record, or a CD.

  data is stored on a SURFACE of a platter. Each platter can have
    one or two surfaces.

  all platters are tied together and rotate around the SPINDLE
    at a fixed speed.

  each surface has one or more READ/WRITE HEADS.

  Platters are broken down into TRACKS.  A single track is
    one of many concentric circles on the platter.

  All the corresponding tracks on all surfaces, taken together,
    form a CYLINDER.

  Each track is broken down into SECTORS.


How we read/write to a sector.
  Given:  the sector position on the cylinder. (looked up in a
  table, or calculated from the disk address).

  -- the disk is spinning.

  -- the read/write head is moving to the correct cylinder (track).
     THIS TAKES A LONG TIME RELATIVE TO THE OTHER STUFF.  It is
     the physical movement, acceleration, etc. that takes lots of
     time.  This is SEEK time.

  -- once the read/write head is over the correct cylinder, there
     is bound to be some time to wait until the correct sector
     is under the head.  This is ROTATIONAL LATENCY.
     The worst case is that the desired sector has just partially
     gone by the read/write head.  To read the sector, we must
     wait until the disk spins all the way around to come back
     to the start of the desired sector.

  -- Even at the correct sector, it still takes some time for
     the data to be read/written.  This is the READ or WRITE
     time.


     time to read a sector =   seek time + rotate time + read time.



So, the nitty gritty issue is:  how does the OS accomplish
  I/O requests?  There are 2 possibilities.

  1.  have special I/O instructions
      --  input
	  need to know  which device, how much data, where the
	  data is to go
      --  output
	  need to know  which device, how much data, where the
	  data currently is

      How does the CPU know that the instruction has completed?
	(Is there any need to wait?)
      What happens if the device encounters an error?
        (Does this halt the computer?)

  2.  the solution of choice
      
      overload memory locations to use as communication channels.

      for example,
       address
       0x0000 0000  -|
       .             |   real memory
       .             |
       .             |
       0xffff 0000  -|

       0xffff 0008  - data from keyboard (Keyboard_Data)

       0xffff 0010  - data to display (Display_Data)

   then, by reading (loading) from location 0xffff0008, data
   is requested from the keyboard
   then, by writing (storing) to location 0xffff0010, data
   is sent to the display

     the syscall code in the OS must be (in essence)

     lw  $2, Keyboard_Data     # getc syscall
     return from syscall

       and

     sw  $2, Display_Data      # putc syscall
     return from syscall


     This method of I/O is called MEMORY-MAPPED I/O.


Problems with memory-mapped I/O as currently given:
 -- getc presumably returns once a character has been typed.
    What happens if the user does not type a character?
    Types it on the wrong keyboard?  Goes to get a drink
    of water?

    What happens to the data if the user types 2 characters
    before getc has been called?

    How does the computer know if a character has been typed?

 -- putc and puts:  how does the computer know that the device
    is ready to print out a second character?  What if the
    printer jams?  (printers and terminals are SLOW!)

 What is needed is a way to convey information about the
 STATUS of I/O devices.  This status information is used
 to coordinate and SYNCHRONIZE the useage of devices.

       address
       0x0000 0000  -|
       .             |   real memory
       .             |
       .             |
       0xffff 0000  -|

       0xffff 0008  - data from keyboard (Keyboard_Data)
       0xffff 000c  - STATUS from keyboard (Keyboard_Status)

       0xffff 0010  - data to display (Display_Data)
       0xffff 0014  - STATUS from display (Display_Status)

  assume that the MSB is used to tell the status of a device.
    MSB = 1 means device ready
    MSB = 0 means device is busy (not ready)
  note that we can check for device ready/busy by looking to see
    if the Status word is negative (2's comp) or not.

    for the keyboard, a 1 means that a character has been typed
		      a 0 means that no character is available

    for the display,  a 1 means that a new character may be sent
		      a 0 means that the device is still disposing
		         of a previous character


Then, the syscall code in the OS must be more like


     getc_loop: lw $8, Keyboard_Status   # getc syscall
		bgez $8, getc_loop
                lw  $2, Keyboard_Data    
                return from syscall      # back to the user-level application


     putc_loop: lw $8, Display_Status    # putc syscall
		bgez $8, putc_loop
                sw  $4, Display_Data
                return from syscall      # back to the user-level application


   This scheme is known as BUSY WAITING, or SPIN WAITING.
   The little loop is called a SPIN WAIT LOOP.



Something that is not well explained (at this level) is how
these status bits get set and cleared.  The spin wait loop
reads the status word, but does not change it.

  The device (its CONTROLLER) sets and clears the bit.
  An implied function is that the device sets the bit
  when it becomes ready to work on another character.

  AND, a load from Keyboard_Data also clears the MSB of Keyboard_Status
  AND, a store to Display_Data also clears the MSB of Display_Status



      -------------                           -------------
      |processor  |  <--------------------->  |  memory   |
      -------------                   |       -------------
                                      |
                                      |
                     controller       |
     -----------      ----------      |
     | display | <--> | Status |<---->|
     -----------      |  Data  |      |
                      ----------      |
                                      |
                                      |
                     controller       |
    ------------      ----------      |
    | keyboard | <--> | Status |<---->|
    ------------      |  Data  |      |
                      ----------      |
                                      |

Note that each device is "hooked up" and operates the same way
with respect to the interaction between processor and memory and
the device.  In fact, any new device that can operate in this manner
can be added to this computer system.  This is an important feature.




PROBLEMS with this programmed I/O approach:

-- much time is wasted spin waiting.

   if it takes 100 instructions to program this, and each
   instruction takes 20ns to execute, then it takes

     100 * 20nsec = 2000nsec = 2 usec    to execute this code

     if a device takes 2msec (=2000usec) to deal with one character,
        then the percent of time spent waiting is

	time waiting       2000us
	------------ = --------------- =  .999 = 99.9%
	total time      2000us + 2usec


   We'd like a solution that spent less time "doing nothing"

-- if (somehow) a second key is pressed before the program does
   a getc, the first key pressed is lost.  There is only one
   character's worth of storage.

   This problem is actually a "Catch-22."  The getc code has
   to be run often enough that no characters are lost, but
   executing this code spin waits until a character is pressed.
   The system could do nothing but getc calls!




Some problems are solved by the use of queues (buffers).
   The check for device ready is separated from the sending
   and receiving of characters.  Code for this is in the
   text, pages 301 and 302.

   FOR THE DISPLAY:
   putnextchar:  Print a character if there is one in the
		 queue, and the device is ready.
		 This routine must be called at regular intervals,
		 so that there is progress toward emptying the queue.
   printstring:  put character(s) in queue and return.  This is called
                 by the user level program when it desires to do
                 a putc or puts.


   FOR THE KEYBOARD:
   getnextchar:  Get a character if one is available, and put
		 it in a queue.
		 This routine must be called at regular intervals,
		 so that characters typed on the keyboard are not
		 missed.
   getstring:    get character from queue (if available) and return



Some difficulties are caused by this situation:
  
 -- Someone (user?  OS?) must call getnextchar regularly and
    often so as not to lose characters.

 -- What happens if the queue(s) become full?  Are characters
    lost?

 -- Someone (user?  OS?) must call putnextchar regularly to empty
    out the queue.
</pre>

<html>
<head>
<title> Lecture notes - Chapter 11 - I/O</title>
</head>

<BODY>
<h1> more on I/O and DMA</h1>

<pre>


  on polling
---------------

to make a system work, the OS will need to check regularly if
its devices have become ready.  This is called polling.

The OS runs at regular intervals (say, once per millisecond)
to check each device to see if it is ready.  If ready, then the
OS further deals with the device.
  For a keyboard, the character typed is placed into a queue.
  For a display, the queue is checked.  If not empty, then the next
    character in the queue is sent to the device.


Difficulties with this:

-- how often to get the OS to poll?
   Too little, and input devices may lose data.
   Too much, and lots of time is wasted checking devices when they are
   not yet ready.
-- How does the OS code get run?
   The user-level program shouldn't have the responsibility.  It has
   no notion of time.
   What happens to the user-level program while the OS is polling?





  on DMA (Direct Memory Access)
---------------------------------

The scheme presented so far really only deals with transfers of a
single byte or word.  There are plenty of devices (networks, disks)
that transfer larger blocks of data.  These devices also tend to
operate much faster than the displays and keyboards and mice.

Having the OS spin wait, or even poll a high speed I/O device
(like a disk) would be really inefficent.  Spin waiting to transfer
a relatively large quantity of data ties up
the processor, and polling couldn't be done often enough to make
it efficient (for high-speed devices).

The solution desired will allow block transfers at the speed that
the device can handle.

  So, set up a simple computer (a controller) that can directly
  access main memory.


    -----------          -----------------           --------------
    |         |          |               |           |            |
    | disk    |<-------->|  controller   |<--------->| memory     |
    |         |          -----------------     / \   |            |
    |         |                                 |    |            |
    -----------                                 |    --------------
						|
					       \ /
                                         ---------------
					 |             |
					 | processor   |
					 |             |
                                         ---------------

The processor sets everything up for a DMA transfer.
It tells the controller
     a starting disk address
     a starting memory address
     # of bytes to transfer
And, then it tells the controller to do the transfer.
The controller does the tranfer (at the speed that the disk can handle).
The processor checks every once in a while (polls) to see if the tranfer
is complete.


An issue to ponder:
  While the disk is reading/writing memory, the processor cannot
  access memory.  How will the processor do anything productive
  if it cannot access memory?

  Solutions:
  -- set up a protocol for the access to memory.  Give the processor
     priority.
  -- design a memory that can handle 2 requests at the same time.
     (Note that this is not practical from a design standpoint.)
  -- don't worry about it, since the disk doesn't need every cycle
     of memory access time.  And, if the processor has a cache (ch. 13)
     the processor won't need much access to memory anyway.

</pre>
